[
{"title": "Deep residual learning for image recognition", "link": "http://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html", "cited": "Cited by 73973", "relatedLink": "https://scholar.google.com/scholar?q=related:LrPNPdmMzoAJ:scholar.google.com/&scioq=Residual+learning&hl=en&oe=ASCII&as_sdt=0,5", "position": 1, "numOfVersions": "All 55 versions", "numOfVersionsLink": "https://scholar.google.com/scholar?cluster=9281510746729853742&hl=en&oe=ASCII&as_sdt=0,5", "publishedData": "K He, X Zhang, S Ren, J Sun\u00a0- Proceedings of the IEEE\u00a0\u2026, 2016 - openaccess.thecvf.com", "snippet": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer\u00a0\u2026"},
{"title": "Multimodal residual learning for visual qa", "link": "https://arxiv.org/abs/1606.01455", "cited": "Cited by 228", "relatedLink": "https://scholar.google.com/scholar?q=related:tFhXwZt6ddQJ:scholar.google.com/&scioq=Residual+learning&hl=en&oe=ASCII&as_sdt=0,5", "position": 2, "numOfVersions": "All 12 versions", "numOfVersionsLink": "https://scholar.google.com/scholar?cluster=15309277317698115764&hl=en&oe=ASCII&as_sdt=0,5", "publishedData": "JH Kim, SW Lee, DH Kwak, MO Heo, J Kim\u2026\u00a0- arXiv preprint arXiv\u00a0\u2026, 2016 - arxiv.org", "snippet": "Deep neural networks continue to advance the state-of-the-art of image recognition tasks with various methods. However, applications of these methods to multimodality remain limited. We present Multimodal Residual Networks (MRN) for the multimodal residual \u00a0\u2026"},
{"title": "Beyond a gaussian denoiser: Residual learning of deep cnn for image denoising", "link": "https://ieeexplore.ieee.org/abstract/document/7839189/", "cited": "Cited by 2941", "relatedLink": "https://scholar.google.com/scholar?q=related:UUn5DRaDbnQJ:scholar.google.com/&scioq=Residual+learning&hl=en&oe=ASCII&as_sdt=0,5", "position": 3, "numOfVersions": "All 10 versions", "numOfVersionsLink": "https://scholar.google.com/scholar?cluster=8389787286584772945&hl=en&oe=ASCII&as_sdt=0,5", "publishedData": "K Zhang, W Zuo, Y Chen, D Meng\u2026\u00a0- IEEE transactions on\u00a0\u2026, 2017 - ieeexplore.ieee.org", "snippet": "The discriminative model learning for image denoising has been recently attracting considerable attentions due to its favorable denoising performance. In this paper, we take one step forward by investigating the construction of feed-forward denoising convolutional\u00a0\u2026"},
{"title": "Deep residual learning for image steganalysis", "link": "https://link.springer.com/article/10.1007/s11042-017-4440-4", "cited": "Cited by 235", "relatedLink": "https://scholar.google.com/scholar?q=related:1N0s5BrEfPYJ:scholar.google.com/&scioq=Residual+learning&hl=en&oe=ASCII&as_sdt=0,5", "position": 4, "numOfVersions": "All 6 versions", "numOfVersionsLink": "https://scholar.google.com/scholar?cluster=17761286650218733012&hl=en&oe=ASCII&as_sdt=0,5", "publishedData": "S Wu, S Zhong, Y Liu\u00a0- Multimedia tools and applications, 2018 - Springer", "snippet": "Image steganalysis is to discriminate innocent images and those suspected images with hidden messages. This task is very challenging for modern adaptive steganography, since modifications due to message hiding are extremely small. Recent studies show that\u00a0\u2026"},
{"title": "Crest: Convolutional residual learning for visual tracking", "link": "http://openaccess.thecvf.com/content_iccv_2017/html/Song_CREST_Convolutional_Residual_ICCV_2017_paper.html", "cited": "Cited by 389", "relatedLink": "https://scholar.google.com/scholar?q=related:jVpgNy_57i8J:scholar.google.com/&scioq=Residual+learning&hl=en&oe=ASCII&as_sdt=0,5", "position": 5, "numOfVersions": "All 9 versions", "numOfVersionsLink": "https://scholar.google.com/scholar?cluster=3453971945427589773&hl=en&oe=ASCII&as_sdt=0,5", "publishedData": "Y Song, C Ma, L Gong, J Zhang\u2026\u00a0- Proceedings of the\u00a0\u2026, 2017 - openaccess.thecvf.com", "snippet": "Discriminative correlation filters (DCFs) have\\ryn been shown to perform superiorly in visual tracking. They\\ryn only need a small set of training samples from the initial frame to generate an appearance model. However, existing DCFs learn the filters separately from feature\u00a0\u2026"},
{"title": "Fixup initialization: Residual learning without normalization", "link": "https://arxiv.org/abs/1901.09321", "cited": "Cited by 127", "relatedLink": "https://scholar.google.com/scholar?q=related:AW0EAJYNh48J:scholar.google.com/&scioq=Residual+learning&hl=en&oe=ASCII&as_sdt=0,5", "position": 6, "numOfVersions": "All 5 versions", "numOfVersionsLink": "https://scholar.google.com/scholar?cluster=10342250007176178945&hl=en&oe=ASCII&as_sdt=0,5", "publishedData": "H Zhang, YN Dauphin, T Ma\u00a0- arXiv preprint arXiv:1901.09321, 2019 - arxiv.org", "snippet": "Normalization layers are a staple in state-of-the-art deep neural network architectures. They are widely believed to stabilize training, enable higher learning rate, accelerate convergence and improve generalization, though the reason for their effectiveness is still an\u00a0\u2026"},
{"title": "Cascade residual learning: A two-stage convolutional neural network for stereo matching", "link": "https://openaccess.thecvf.com/content_ICCV_2017_workshops/w17/html/Pang_Cascade_Residual_Learning_ICCV_2017_paper.html", "cited": "Cited by 266", "relatedLink": "https://scholar.google.com/scholar?q=related:S5gVi5RXF40J:scholar.google.com/&scioq=Residual+learning&hl=en&oe=ASCII&as_sdt=0,5", "position": 7, "numOfVersions": "All 8 versions", "numOfVersionsLink": "https://scholar.google.com/scholar?cluster=10166690979312408651&hl=en&oe=ASCII&as_sdt=0,5", "publishedData": "J Pang, W Sun, JSJ Ren, C Yang\u2026\u00a0- Proceedings of the\u00a0\u2026, 2017 - openaccess.thecvf.com", "snippet": "Leveraging on the recent developments in convolutional neural networks (CNNs), matching dense correspondence from a stereo pair has been cast as a learning problem, with performance exceeding traditional approaches. However, it remains challenging to generate\u00a0\u2026"},
{"title": "Recurrent residual learning for sequence classification", "link": "https://www.aclweb.org/anthology/D16-1093.pdf", "cited": "Cited by 85", "relatedLink": "https://scholar.google.com/scholar?q=related:0CzsW27sU9wJ:scholar.google.com/&scioq=Residual+learning&hl=en&oe=ASCII&as_sdt=0,5", "position": 8, "numOfVersions": "All 6 versions", "numOfVersionsLink": "https://scholar.google.com/scholar?cluster=15876293070143892688&hl=en&oe=ASCII&as_sdt=0,5", "publishedData": "Y Wang, F Tian\u00a0- Proceedings of the 2016 conference on empirical\u00a0\u2026, 2016 - aclweb.org", "snippet": "In this paper, we explore the possibility of leveraging Residual Networks (ResNet), a powerful structure in constructing extremely deep neural network for image understanding, to improve recurrent neural networks (RNN) for modeling sequential data. We show that for\u00a0\u2026"},
{"title": "Attention residual learning for skin lesion classification", "link": "https://ieeexplore.ieee.org/abstract/document/8620285/", "cited": "Cited by 95", "relatedLink": "https://scholar.google.com/scholar?q=related:2yUzIOctv38J:scholar.google.com/&scioq=Residual+learning&hl=en&oe=ASCII&as_sdt=0,5", "position": 9, "numOfVersions": "All 7 versions", "numOfVersionsLink": "https://scholar.google.com/scholar?cluster=9205126634069501403&hl=en&oe=ASCII&as_sdt=0,5", "publishedData": "J Zhang, Y Xie, Y Xia, C Shen\u00a0- IEEE transactions on medical\u00a0\u2026, 2019 - ieeexplore.ieee.org", "snippet": "Automated skin lesion classification in dermoscopy images is an essential way to improve the diagnostic performance and reduce melanoma deaths. Although deep convolutional neural networks (DCNNs) have made dramatic breakthroughs in many image classification\u00a0\u2026"},
{"title": "Shakedrop regularization for deep residual learning", "link": "https://ieeexplore.ieee.org/abstract/document/8936428/", "cited": "Cited by 66", "relatedLink": "https://scholar.google.com/scholar?q=related:IxD67g2gYUUJ:scholar.google.com/&scioq=Residual+learning&hl=en&oe=ASCII&as_sdt=0,5", "position": 10, "numOfVersions": "All 3 versions", "numOfVersionsLink": "https://scholar.google.com/scholar?cluster=4999453043062345763&hl=en&oe=ASCII&as_sdt=0,5", "publishedData": "Y Yamada, M Iwamura, T Akiba, K Kise\u00a0- IEEE Access, 2019 - ieeexplore.ieee.org", "snippet": "Overfitting is a crucial problem in deep neural networks, even in the latest network architectures. In this paper, to relieve the overfitting effect of ResNet and its improvements (ie, Wide ResNet, PyramidNet, and ResNeXt), we propose a new regularization method\u00a0\u2026"}
]